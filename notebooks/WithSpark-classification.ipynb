{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yaml import load as yaml_load\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "sys.path.append('../')\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql.types import LongType\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression, GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler, VectorIndexer, StandardScaler\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, pandas_udf, udf\n",
    "from pyspark.sql.types import LongType, StringType, FloatType, IntegerType, DoubleType\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "import re\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"Data cleaning\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.make_dataset import LoadDataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_config_file(config_file):\n",
    "    \"\"\"\n",
    "    Load configuration file\n",
    "    :param config_file: is the configuration file\n",
    "    :return: configuration\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    with open(config_file) as yml_config:\n",
    "        return yaml_load(yml_config)\n",
    "\n",
    "def _build_configuration(config_file):\n",
    "    \"\"\"\n",
    "    Build the operation configuration dict\n",
    "    :param config_file: is the path to the yaml config_file\n",
    "    :type: string\n",
    "    :return: config: global configuration\n",
    "    :rtype dict\n",
    "    \"\"\"\n",
    "    # yaml config\n",
    "    config = _load_config_file(config_file)\n",
    "    return config\n",
    "def visualisation_prediction(y_test, y_pred):\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    matplotlib.rc('xtick', labelsize=30) \n",
    "    matplotlib.rc('ytick', labelsize=30) \n",
    "    fig, ax = plt.subplots(figsize=(50, 40))\n",
    "    plt.style.use('ggplot')\n",
    "    plt.plot(y_pred, y_test, 'ro')\n",
    "    plt.xlabel('Predicted Crime', fontsize = 30)\n",
    "    plt.ylabel('Actual Crime', fontsize = 30)\n",
    "    plt.title('Predicted Y (Crimes) to the Actual Y (Crimes)', fontsize = 30)\n",
    "    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "    \n",
    "    \n",
    "def duration_day_func(x):\n",
    "    \"\"\"\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    from astral import Astral\n",
    "    city_name = 'Chicago'\n",
    "    a = Astral()\n",
    "    a.solar_depression = 'civil'\n",
    "    city = a[city_name]\n",
    "    sun = city.sun(date=x, local=True)\n",
    "    return float((sun['sunset'] - sun['sunrise']).total_seconds())\n",
    "\n",
    "extract_blok = udf(lambda x : re.findall(r\"(\\w+)$\", x)[0], StringType())\n",
    "isStreet = udf(lambda x :  1 if x in ['ST', 'St', 'st'] else 0, DoubleType())\n",
    "isAV = udf(lambda x : 1 if x in ['Ave', 'AV', 'AVE'] else 0, DoubleType())\n",
    "isBLVD = udf(lambda x : 1 if x in ['BLVD'] else 0, DoubleType())\n",
    "isRD = udf(lambda x : 1 if x in ['RD'] else 0, DoubleType())\n",
    "isPL = udf(lambda x : 1 if x in ['PL', 'pl'] else 0, DoubleType())\n",
    "isBROADWAY = udf(lambda x : 1 if x in ['BROADWAY', 'Broadway'] else 0, DoubleType())\n",
    "isPKWY = udf(lambda x : 1 if x in ['PKWY', 'Pkwy'] else 0, DoubleType())\n",
    "duration_day_udf = udf(lambda x :   duration_day_func(x),  DoubleType())\n",
    "\n",
    "config_file = \"/home/ml/Documents/crimes_chigaco/config/config.yml\"\n",
    "config = _build_configuration(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "obj_df_loaded = LoadDataframe(config, '2013', '2014')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = obj_df_loaded.df_temperature()\n",
    "df_sky  = obj_df_loaded.df_sky()\n",
    "df_socio = obj_df_loaded.df_socio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_socio = ['pct_housing_crowded',\n",
    " 'pct_households_below_poverty','pct_age16_unemployed',\n",
    " 'pct_age25_no_highschool',\n",
    " 'pct_not_working_age',\n",
    " 'per_capita_income',\n",
    " 'hardship_index']\n",
    "for f in features_socio:\n",
    "    df_socio = df_socio.withColumn(f, df_socio[f].cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime = obj_df_loaded.df_crime()\n",
    "df_crime_socio = df_crime.join(df_socio, ['community_area_number'], \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime_socio = df_crime_socio.withColumn(\"block_extract\", extract_blok(df_crime_socio.block))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime_socio = df_crime_socio.withColumn(\"isStreet\", isStreet(df_crime_socio.block_extract)).withColumn(\"isAV\", isAV(df_crime_socio.block_extract)).withColumn(\"isBLVD\", isBLVD(df_crime_socio.block_extract)).withColumn(\"isRD\", isRD(df_crime_socio.block_extract)).withColumn(\"isPL\", isPL(df_crime_socio.block_extract)).withColumn(\"isBROADWAY\", isBROADWAY(df_crime_socio.block_extract)).withColumn(\"isPKWY\", isPKWY(df_crime_socio.block_extract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime_socio = df_crime_socio.withColumn('duree_day', duration_day_udf('date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime_socio = (\n",
    "df_crime_socio.withColumn(\"month\", func.month(func.col(\"date\"))).\n",
    "withColumn(\"year\", func.year(func.col(\"date\"))).\n",
    "withColumn(\"day\", func.dayofmonth(func.col(\"date\"))).\n",
    "withColumn(\"hour\", func.hour(func.col(\"date\"))).withColumn(\"minute\", func.minute(func.col(\"date\"))).\n",
    "withColumn(\"dayofmonth\", func.dayofmonth(func.col(\"date\"))).   \n",
    "withColumn(\"dayofyear\", func.dayofyear(func.col(\"date\"))).\n",
    "withColumn(\"dayofweek\", func.dayofweek(func.col(\"date\")))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = df_crime_socio.join(df_temp, ['year', 'month','day','hour'], how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = df_total.withColumn('latitude', df_total['latitude'].cast(FloatType()))\n",
    "df_total = df_total.withColumn('longitude', df_total['longitude'].cast(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_crimes = config[\"List_of_crimes_prediction\"][\"with_merge_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_total.where(col('primary_type').isin(list_of_crimes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalColumns = ['domestic']\n",
    "numericCols = ['year', 'month', 'day', 'hour','minute', 'latitude', 'longitude', 'isStreet', 'isAV', 'isBLVD', 'isRD', 'isPL', 'isBROADWAY', 'isPKWY']\n",
    "stages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for categoricalCol in categoricalColumns:\n",
    "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "    encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_stringIdx = StringIndexer(inputCol = 'primary_type', outputCol = 'label')\n",
    "stages += [label_stringIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages = stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineModel = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipelineModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedCols = ['label', 'features'] + categoricalColumns + numericCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(selectedCols)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy('label').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
