{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yaml import load as yaml_load\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "sys.path.append('../')\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql.types import LongType\n",
    "from pyspark.sql.functions import isnan, when, count, col, isnull\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression, GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler, VectorIndexer, StandardScaler\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, pandas_udf, udf\n",
    "from pyspark.sql.types import LongType, StringType, FloatType, IntegerType, DoubleType\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "import re\n",
    "from pyspark.ml.classification import RandomForestClassifier, RandomForestClassificationModel, GBTClassifier,OneVsRest, OneVsRestModel\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString, RFormula\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Data cleaning\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.make_dataset import LoadDataframe\n",
    "from src.features.build_features import extract_features_classification\n",
    "from src.models.train_model import model_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_config_file(config_file):\n",
    "    \"\"\"\n",
    "    Load configuration file\n",
    "    :param config_file: is the configuration file\n",
    "    :return: configuration\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    with open(config_file) as yml_config:\n",
    "        return yaml_load(yml_config)\n",
    "\n",
    "def _build_configuration(config_file):\n",
    "    \"\"\"\n",
    "    Build the operation configuration dict\n",
    "    :param config_file: is the path to the yaml config_file\n",
    "    :type: string\n",
    "    :return: config: global configuration\n",
    "    :rtype dict\n",
    "    \"\"\"\n",
    "    # yaml config\n",
    "    config = _load_config_file(config_file)\n",
    "    return config\n",
    "def visualisation_prediction(y_test, y_pred):\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    matplotlib.rc('xtick', labelsize=30) \n",
    "    matplotlib.rc('ytick', labelsize=30) \n",
    "    fig, ax = plt.subplots(figsize=(50, 40))\n",
    "    plt.style.use('ggplot')\n",
    "    plt.plot(y_pred, y_test, 'ro')\n",
    "    plt.xlabel('Predicted Crime', fontsize = 30)\n",
    "    plt.ylabel('Actual Crime', fontsize = 30)\n",
    "    plt.title('Predicted Y (Crimes) to the Actual Y (Crimes)', fontsize = 30)\n",
    "    ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "    \n",
    "\n",
    "config_file = \"/home/ml/Documents/Crime_Chigaco_Spark/config/config.yml\"\n",
    "config = _build_configuration(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 349 µs, sys: 45 µs, total: 394 µs\n",
      "Wall time: 400 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "obj_df_loaded = LoadDataframe(config, '2013', '2014')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/spark/spark-2.4.0-bin-hadoop2.7/python/pyspark/sql/dataframe.py:1793: UserWarning: to_replace is a dict and value is not None. value will be ignored.\n",
      "  warnings.warn(\"to_replace is a dict and value is not None. value will be ignored.\")\n"
     ]
    }
   ],
   "source": [
    "df_crimes_socio = obj_df_loaded.df_crime_socio()\n",
    "df_temp = obj_df_loaded.df_temperature()\n",
    "df_sky  = obj_df_loaded.df_sky()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_extract_features_classification = extract_features_classification(config, df_crimes_socio, df_temp, df_sky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_ml = obj_extract_features_classification.extract_feature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obj_model_classification = model_classification(config, df_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.86 s, sys: 1.24 s, total: 6.1 s\n",
      "Wall time: 54min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_model = obj_model_classification.train_RF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = obj_model_classification.df_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction = rf_model.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_type</th>\n",
       "      <th>label</th>\n",
       "      <th>prediction</th>\n",
       "      <th>predictedLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASSAULT_BATTERY</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ASSAULT_BATTERY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NARCOTICS</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ASSAULT_BATTERY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>THEFT_ROBBERY_BURGLARY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>THEFT_ROBBERY_BURGLARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THEFT_ROBBERY_BURGLARY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>THEFT_ROBBERY_BURGLARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>THEFT_ROBBERY_BURGLARY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>THEFT_ROBBERY_BURGLARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>THEFT_ROBBERY_BURGLARY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>THEFT_ROBBERY_BURGLARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASSAULT_BATTERY</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>THEFT_ROBBERY_BURGLARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>THEFT_ROBBERY_BURGLARY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>THEFT_ROBBERY_BURGLARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NARCOTICS</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>THEFT_ROBBERY_BURGLARY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>THEFT_ROBBERY_BURGLARY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>THEFT_ROBBERY_BURGLARY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             primary_type  label  prediction          predictedLabel\n",
       "0         ASSAULT_BATTERY    1.0         1.0         ASSAULT_BATTERY\n",
       "1               NARCOTICS    2.0         1.0         ASSAULT_BATTERY\n",
       "2  THEFT_ROBBERY_BURGLARY    0.0         0.0  THEFT_ROBBERY_BURGLARY\n",
       "3  THEFT_ROBBERY_BURGLARY    0.0         0.0  THEFT_ROBBERY_BURGLARY\n",
       "4  THEFT_ROBBERY_BURGLARY    0.0         0.0  THEFT_ROBBERY_BURGLARY\n",
       "5  THEFT_ROBBERY_BURGLARY    0.0         0.0  THEFT_ROBBERY_BURGLARY\n",
       "6         ASSAULT_BATTERY    1.0         0.0  THEFT_ROBBERY_BURGLARY\n",
       "7  THEFT_ROBBERY_BURGLARY    0.0         0.0  THEFT_ROBBERY_BURGLARY\n",
       "8               NARCOTICS    2.0         0.0  THEFT_ROBBERY_BURGLARY\n",
       "9  THEFT_ROBBERY_BURGLARY    0.0         0.0  THEFT_ROBBERY_BURGLARY"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prediction.select('primary_type','label', 'prediction','predictedLabel').limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
